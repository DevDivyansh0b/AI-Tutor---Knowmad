# -*- coding: utf-8 -*-
"""AIsha.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x52Bzq97iz-d_T9JwgNhIFNfzIfUecaw
"""

!pip install -q -U google-generativeai
!pip install openai
!pip install gradio gtts pytube
!pip install google-api-python-client
!curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw

import pathlib
import textwrap
from openai import OpenAI
import google.generativeai as genai
from IPython.display import display
from IPython.display import Markdown
import os
from googleapiclient.discovery import build
from datetime import timedelta
from google.colab import userdata
import PIL.Image
from IPython.display import YouTubeVideo
from IPython.display import Audio
import gradio as gr
from gtts import gTTS
import requests
from io import BytesIO
from pytube import YouTube

def to_markdown(text):
  text = text.replace('â€¢', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

GOOGLE_API_KEY=userdata.get('gemini_api_key')
genai.configure(api_key=GOOGLE_API_KEY)
chat_model = genai.GenerativeModel('gemini-pro')
chat = chat_model.start_chat(history=[])
OpenAI.api_key =userdata.get('openai_api_key')
client = OpenAI(api_key=OpenAI.api_key)
yt_api_key = userdata.get('yt_api_key')
youtube = build('youtube', 'v3', developerKey=yt_api_key)
seeing_model = genai.GenerativeModel('gemini-pro')

img = PIL.Image.open('/content/test_notes_1.jpg')

audio_file= open("/content/Recording.m4a", "rb")
text_input="Hi can u explain me moment area method from these notes?"

def text_extractor(img):
  model = genai.GenerativeModel('gemini-pro-vision')
  response = model.generate_content(["these are notes of a topic, extract all the text from this image and make them such that they look relevant to the topic moment area theoram", img], stream=True)
  response.resolve()
  return response.text

def chat_with_AIsha(text_input):
  #audio_instruction=audio_to_text(audio_file)
  response = chat.send_message(text_input)
  return to_markdown(response.text)

def audio_to_text(audio_file):
  transcription = client.audio.transcriptions.create(
  model="whisper-1",
    file=audio_file
  )
  return transcription.text

def search_videos(query):
    request = youtube.search().list(
        part="snippet",
        q=query,
        type="video",
        maxResults=1
    )
    response = request.execute()
    return response['items'][0]['id']['videoId']

def youtube_video(video_url):
    yt = YouTube(video_url)
    video = yt.streams.get_highest_resolution().download()
    return video

def timestamp_identifier(yt_video_url,query):
  seeing_response = seeing_model.generate_content(yt_video_url+" using this youtube video and user's query,see the relevant time stamps that are useful in the video to start from and give that particular url such that video starts from there, don't write anything else, just write the url, the query is: "+query)
  return seeing_response.text

def convert_to_speech(text):
  speech_file_path ="/content/output.mp3"
  response = client.audio.speech.create(
    model="tts-1",
    voice="alloy",
    input=text
  )
  response.stream_to_file(speech_file_path)
  return Audio(speech_file_path, autoplay=True)

def topic_identifier(img):
  notes_text=text_extractor(img)
  model = genai.GenerativeModel('gemini-pro')
  response = model.generate_content(notes_text+"these are notes of a topic, give topic to which they belong")
  return response.text
img = PIL.Image.open('/content/test_notes_1.jpg')

def app(user_input, uploaded_image):
    notes_text=text_extractor(img)
    print("1")
    model = genai.GenerativeModel('gemini-pro')
    response = model.generate_content(notes_text+"these are notes of a topic"+topic_identifier(img)+", give the name of only one yt video that is most relevant to the topic, don't write anything else")
    query=response.text
    print("1")
    youtube_url='https://www.youtube.com/watch?v='+search_videos(query)
    video_file = youtube_video(youtube_url)
    print("1")
    # Your text processing code here to generate output_text
    text_response=model.generate_content(notes_text+"these are notes of a topic"+topic_identifier(img)+user_input)
    output_text=text_response.text
    print("1")
    return output_text,video_file

app("explain step by step on how to solve a question by moment area method",img)

gr.Interface(
    fn=app,
    inputs=[
        gr.Textbox(label="Enter Text"),
        gr.Image(label="Upload Image"),
    ],
    outputs=[
        gr.Textbox(label="Output Text"),
        gr.Video(label="Output Video")
    ],
    title="AIsha",
    description="Your AI tutor."
).launch()







